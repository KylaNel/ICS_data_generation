{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Reshape, Conv2DTranspose, UpSampling2D, Lambda\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get in dataset\n",
    "data_features_test = pd.read_csv(\"datasets/energy-informatics-2020/csvDataFeaturesTest.csv\", sep=\";\")\n",
    "\n",
    "# Take out only data corresponing to attacks and remove the column labelling it as an attack\n",
    "data_features_attacks = data_features_test.to_numpy()[238279:, :21]\n",
    "data_features_attacks.shape\n",
    "data_features_attacks = data_features_attacks.reshape(9999,21,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reparameterisation\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_vars = args\n",
    "    batch = np.shape(z_mean)[0]\n",
    "    dim = keras.backend.int_shape(z_mean)[1]\n",
    "    epsilon = keras.backend.random_normal(shape=keras.backend.shape(z_mean), mean=0., stddev=1.)\n",
    "    return z_mean + keras.backend.exp(0.5 * z_log_var) * epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "\n",
    "def build_encoder(input_layer, latent_dimensions, kernel_size):\n",
    "    # combined convolution and maxpooling 3 times\n",
    "    encoder = Conv2D(64, kernel_size, activation='relu', padding='same')(input_layer)\n",
    "    encoder = MaxPooling2D((2,2))(encoder)\n",
    "    encoder = Conv2D(32, kernel_size, activation='relu', padding='same')(encoder)\n",
    "    encoder = MaxPooling2D((2,2))(encoder)\n",
    "    encoder = Conv2D(16, kernel_size, activation='relu', padding='same')(encoder)\n",
    "    encoder = MaxPooling2D((2,2))(encoder)\n",
    "    encoder = Conv2D(8, kernel_size, activation='relu', padding='same')(encoder)\n",
    "\n",
    "    # flatten data\n",
    "    encoder_shape = keras.backend.int_shape(encoder)[1:]\n",
    "    encoder = Reshape((np.prod(encoder_shape),))(encoder)\n",
    "\n",
    "    # feed mean and log variance into reparameterisation function for a sampled output\n",
    "    z_mean = layers.Dense(latent_dimensions, activation='linear')(encoder)\n",
    "    z_log_var = layers.Dense(latent_dimensions, activation='linear')(encoder)\n",
    "    # reparametrisation\n",
    "    z = Lambda(sampling, output_shape=(latent_dimensions,))([z_mean, z_log_var])\n",
    "\n",
    "    model = keras.Model(input_layer, [z_mean, z_log_var, z], name='encoder')\n",
    "    return model, z_mean, z_log_var, encoder_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "\n",
    "def build_decoder(latent_dimensions, kernel_size, encoder_shape, input_shape):\n",
    "    lats = keras.Input(shape=(latent_dimensions,))\n",
    "    #reshape latent space back into shape of processed data and flatten\n",
    "    decoder = Dense(np.prod(encoder_shape), activation='relu')(lats)\n",
    "    decoder = Reshape(encoder_shape)(decoder)\n",
    "\n",
    "    #layer then convolved and upsampled in reverse order of encoder to product data the same shape as the original input\n",
    "    decoder = Conv2DTranspose(16, kernel_size, activation='relu', padding='same')(decoder)\n",
    "    decoder = UpSampling2D((2,2))(decoder)\n",
    "    decoder = Conv2DTranspose(32, kernel_size, activation='relu', padding='same')(decoder)\n",
    "    decoder = UpSampling2D((2,2))(decoder)\n",
    "    decoder = Conv2DTranspose(64, kernel_size, activation='relu', padding='same')(decoder)\n",
    "    decoder = UpSampling2D((2,2))(decoder)\n",
    "\n",
    "    outputs = Conv2DTranspose(3, kernel_size, activation='relu', padding='same')(decoder)\n",
    "\n",
    "    model = keras.Model(lats, outputs, name='decoder')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder\n",
    "\n",
    "def build_autoencoder(encoder, decoder, input_layer, z_mean, z_log_var):\n",
    "    output_layer = decoder(encoder(input_layer)[2])\n",
    "    vae = keras.Model(input_layer, output_layer, name='autoencoder')\n",
    "\n",
    "    reconstruction_loss = tf.reduce_mean(1000 * tf.square(input_layer-output_layer))\n",
    "\n",
    "    kl_loss = -0.5 * keras.backend.sum(1 + z_log_var - keras.backend.square(z_mean) - keras.backend.exp(z_log_var), axis=1)\n",
    "    vae_loss = tf.reduce_mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "    vae.add_loss(vae_loss)\n",
    "    vae.add_metric(tf.reduce_sum(1000*tf.square(input_layer - output_layer)), aggregation='mean')\n",
    "    vae.add_metric(kl_loss, aggregation='mean')\n",
    "    vae.compile(optimizer='adam')\n",
    "\n",
    "    return vae, reconstruction_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "Exception encountered when calling layer \"lambda\" (type Lambda).\n\nname 'z_log_var' is not defined\n\nCall arguments received by layer \"lambda\" (type Lambda):\n  • inputs=['tf.Tensor(shape=(None, 200), dtype=float32)', 'tf.Tensor(shape=(None, 200), dtype=float32)']\n  • mask=None\n  • training=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/knel/virtual_envs/ankh-morpork/autoencoder_test_run.ipynb Cell 7\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/knel/virtual_envs/ankh-morpork/autoencoder_test_run.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m kernel_size \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/knel/virtual_envs/ankh-morpork/autoencoder_test_run.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m input_layer \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39minput_shape)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/knel/virtual_envs/ankh-morpork/autoencoder_test_run.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m encoder, z_mean, z_log_var, encoder_shape \u001b[39m=\u001b[39m build_encoder(input_layer, latent_dimensions, kernel_size)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/knel/virtual_envs/ankh-morpork/autoencoder_test_run.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m decoder \u001b[39m=\u001b[39m build_decoder(latent_dimensions, kernel_size, encoder_shape, input_shape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/knel/virtual_envs/ankh-morpork/autoencoder_test_run.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m autoencoder, reconstruction_loss \u001b[39m=\u001b[39m build_autoencoder(encoder, decoder, input_layer, z_mean, z_log_var)\n",
      "\u001b[1;32m/home/knel/virtual_envs/ankh-morpork/autoencoder_test_run.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/knel/virtual_envs/ankh-morpork/autoencoder_test_run.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m z_log_var \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mDense(latent_dimensions, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m'\u001b[39m)(encoder)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/knel/virtual_envs/ankh-morpork/autoencoder_test_run.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# reparametrisation\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/knel/virtual_envs/ankh-morpork/autoencoder_test_run.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m z \u001b[39m=\u001b[39m Lambda(sampling, output_shape\u001b[39m=\u001b[39;49m(latent_dimensions,))([z_mean, z_log_var])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/knel/virtual_envs/ankh-morpork/autoencoder_test_run.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mModel(input_layer, [z_mean, z_log_var, z], name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mencoder\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/knel/virtual_envs/ankh-morpork/autoencoder_test_run.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model, z_mean, z_log_var, encoder_shape\n",
      "File \u001b[0;32m~/virtual_envs/ankh-morpork/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;32m/home/knel/virtual_envs/ankh-morpork/autoencoder_test_run.ipynb Cell 7\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/knel/virtual_envs/ankh-morpork/autoencoder_test_run.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m dim \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39mint_shape(z_mean)[\u001b[39m1\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/knel/virtual_envs/ankh-morpork/autoencoder_test_run.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m epsilon \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39mrandom_normal(shape\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39mshape(z_mean), mean\u001b[39m=\u001b[39m\u001b[39m0.\u001b[39m, stddev\u001b[39m=\u001b[39m\u001b[39m1.\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/knel/virtual_envs/ankh-morpork/autoencoder_test_run.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mreturn\u001b[39;00m z_mean \u001b[39m+\u001b[39m keras\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39mexp(\u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m z_log_var) \u001b[39m*\u001b[39m epsilon\n",
      "\u001b[0;31mNameError\u001b[0m: Exception encountered when calling layer \"lambda\" (type Lambda).\n\nname 'z_log_var' is not defined\n\nCall arguments received by layer \"lambda\" (type Lambda):\n  • inputs=['tf.Tensor(shape=(None, 200), dtype=float32)', 'tf.Tensor(shape=(None, 200), dtype=float32)']\n  • mask=None\n  • training=None"
     ]
    }
   ],
   "source": [
    "model_name = \"test\"\n",
    "input_shape = data_features_attacks.shape\n",
    "latent_dimensions = 200\n",
    "batch_size = 128\n",
    "epochs = 1\n",
    "kernel_size = 3\n",
    "input_layer = keras.Input(shape=input_shape)\n",
    "\n",
    "encoder, z_mean, z_log_var, encoder_shape = build_encoder(input_layer, latent_dimensions, kernel_size)\n",
    "decoder = build_decoder(latent_dimensions, kernel_size, encoder_shape, input_shape)\n",
    "autoencoder, reconstruction_loss = build_autoencoder(encoder, decoder, input_layer, z_mean, z_log_var)\n",
    "\n",
    "autoencoder.fit(data_features_attacks, epochs=epochs, batch_size=batch_size, shuffle=True)\n",
    "autoencoder.save_weights(model_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ankh-morpork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
