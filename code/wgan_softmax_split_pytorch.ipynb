{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XpnS3F54NaTT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-28 15:35:22.922007: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-02-28 15:35:23.869408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-28 15:35:23.869430: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-28 15:35:23.872415: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-28 15:35:24.348489: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-02-28 15:35:24.350521: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-02-28 15:35:27.104968: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn import preprocessing\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ir3cCqLKNaTT"
      },
      "outputs": [],
      "source": [
        "attacks = pd.read_csv(\"/home/knel/virtual_envs/ankh-morpork/ICS_data_generation/data/swat_processed_sample.csv\", sep=\",\", usecols=range(1,23), skiprows=[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PlGx2v1BNaTT"
      },
      "outputs": [],
      "source": [
        "attacks = preprocessing.normalize(attacks.to_numpy(), norm=\"max\", axis=0)\n",
        "\n",
        "# swap sport to front\n",
        "attacks[:, [0, 1]] = attacks[:, [1, 0]]\n",
        "# swap dport to after sport\n",
        "attacks[:, [1, 2]] = attacks[:, [2, 1]]\n",
        "# swap protocols to after dport\n",
        "attacks[:, [2, 14]] = attacks[:, [14, 2]]\n",
        "\n",
        "# column order now -> sport, dport, protocols, continuous (discrete, discrete, discrete, continuous)\n",
        "\n",
        "\n",
        "\n",
        "# should probably add batch and shuffle\n",
        "\n",
        "train_dataset = attacks[:int(np.floor(attacks.shape[0]*3/4))]\n",
        "test_dataset = attacks[int(np.floor(attacks.shape[0]*3/4)):]\n",
        "\n",
        "num_features = attacks[:int(np.floor(attacks.shape[0]*3/4))].shape[1]\n",
        "seq_length = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ifqu0pgzNaTT",
        "outputId": "2ec21186-565b-4bc1-e717-e15a2ba5dea6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1500, 500)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataset), len(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRR0cUA17sWo",
        "outputId": "7f31e18a-f1c4-4b54-de4a-1f4173faa25e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([7.27481853e-01, 7.99678830e-01, 2.50000000e-01, 1.33689840e-03,\n",
              "       2.29095074e-03, 1.30282912e-03, 1.94383728e-03, 5.15252969e-04,\n",
              "       1.34779820e-04, 5.58035706e-04, 1.02306549e-03, 1.52555301e-03,\n",
              "       7.65110941e-04, 4.49197871e-01, 2.15040043e-03, 2.15040043e-03,\n",
              "       0.00000000e+00, 2.15040043e-03, 2.15040043e-03, 2.15040043e-03,\n",
              "       0.00000000e+00, 2.15040043e-03])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTZSt9lp71rK",
        "outputId": "ae479dd0-cd5f-4cfd-cc3f-2b345b0c7a70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([5.53460684e-01, 6.60183781e-04, 2.50000000e-01, 2.67379679e-03,\n",
              "       1.90912562e-03, 5.24761820e-03, 5.48529191e-03, 5.84350684e-05,\n",
              "       1.01134633e-05, 3.20936160e-05, 2.22186570e-05, 2.28832952e-03,\n",
              "       3.06044376e-03, 7.43833008e-01, 8.10130162e-02, 8.10130162e-02,\n",
              "       0.00000000e+00, 8.10130162e-02, 8.10130162e-02, 8.10130162e-02,\n",
              "       0.00000000e+00, 8.10130162e-02])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FZs594sNaTU"
      },
      "outputs": [],
      "source": [
        "# custom loss\n",
        "def wasserstein_loss(y_true, y_pred):\n",
        "    return tf.keras.backend.mean(y_true * y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPAYKjg2NaTU"
      },
      "outputs": [],
      "source": [
        "# clip model weights to a given hypercube\n",
        "class ClipConstraint(tf.keras.constraints.Constraint):\n",
        "\t# set clip value when initialized\n",
        "\tdef __init__(self, clip_value):\n",
        "\t\tself.clip_value = clip_value\n",
        "\n",
        "\t# clip model weights to hypercube\n",
        "\tdef __call__(self, weights):\n",
        "\t\treturn tf.keras.backend.clip(weights, -self.clip_value, self.clip_value)\n",
        "\n",
        "\t# get the config\n",
        "\tdef get_config(self):\n",
        "\t\treturn {'clip_value': self.clip_value}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRvc7NspNaTV"
      },
      "outputs": [],
      "source": [
        "# Wasserstein loss for critic\n",
        "def critic_loss(pred_real, pred_fake):\n",
        "    return tf.keras.backend.mean(pred_real * pred_fake)\n",
        "\n",
        "# Wasserstein loss for generator\n",
        "def generator_loss(pred_fake):\n",
        "    return -tf.keras.backend.mean(pred_fake)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgCI_3rzNaTV"
      },
      "outputs": [],
      "source": [
        "generator_optimiser = tf.keras.optimizers.legacy.RMSprop(learning_rate=0.00005)\n",
        "critic_optimiser = tf.keras.optimizers.legacy.RMSprop(learning_rate=0.00005)\n",
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xlMvaNXAMG9F"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self, _data, num_classes_list):\n",
        "        self.data = torch.tensor(_data, dtype=torch.float32)\n",
        "        self.num_classes_list = num_classes_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "\n",
        "        # One-hot encode each of the first three values with different num_classes\n",
        "        one_hot_encoded_1 = torch.nn.functional.one_hot(sample[0].long(), self.num_classes_list[0])\n",
        "        one_hot_encoded_2 = torch.nn.functional.one_hot(sample[1].long(), self.num_classes_list[1])\n",
        "        one_hot_encoded_3 = torch.nn.functional.one_hot(sample[2].long(), self.num_classes_list[2])\n",
        "        # print(\"1 :\",one_hot_encoded_1.shape)\n",
        "        # print(\"2 :\",one_hot_encoded_2.shape)\n",
        "        # print(\"3 :\",one_hot_encoded_3.shape)\n",
        "        # print(\"4 :\",sample[3:].shape)\n",
        "        # Concatenate one-hot encoding with the remaining values\n",
        "        modified_sample = torch.cat((one_hot_encoded_1.float(), one_hot_encoded_2.float(), one_hot_encoded_3.float(), sample[3:]))\n",
        "\n",
        "        return modified_sample\n",
        "\n",
        "data = np.array(train_dataset[:10000])\n",
        "dataset = Dataset(data,[23030, 14372, 7])\n",
        "\n",
        "batch_size = 64\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "99r4Yc1VZwbI"
      },
      "outputs": [],
      "source": [
        "def differentiable_argmax(gumbel_softmax_sample):\n",
        "    _, max_indices = gumbel_softmax_sample.max(dim=-1, keepdim=True)\n",
        "    one_hot = torch.zeros_like(gumbel_softmax_sample).scatter_(-1, max_indices, 1.0)\n",
        "    return one_hot - gumbel_softmax_sample.detach() + gumbel_softmax_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fPfL8QW8uaqN"
      },
      "outputs": [],
      "source": [
        "def convert_generator_output(output_tensors):\n",
        "    sport_dist, dport_dist, proto_dist, cont = output_tensors\n",
        "    num_samples = sport_dist.size(0)\n",
        "    final = torch.zeros((num_samples, 22))\n",
        "\n",
        "    for sample_index in range(num_samples):\n",
        "        sport = torch.argmax(sport_dist[sample_index]) + 1\n",
        "        dport = torch.argmax(dport_dist[sample_index]) + 1\n",
        "        proto = torch.argmax(proto_dist[sample_index]) + 1\n",
        "\n",
        "        data_point = torch.cat((sport.view(1), dport.view(1), proto.view(1), cont[sample_index]))\n",
        "        final[sample_index] = data_point\n",
        "\n",
        "    return final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4Ee-uh20Eaih",
        "outputId": "60068658-63de-4999-c86d-67599f7dad72"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [00:16<02:28, 16.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], D Loss: 33.056175231933594, G Loss: 2.850388526916504\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 2/10 [00:33<02:12, 16.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], D Loss: 32.42152786254883, G Loss: 2.837352991104126\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 3/10 [00:49<01:56, 16.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], D Loss: 32.24760818481445, G Loss: 2.8269238471984863\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 4/10 [01:06<01:40, 16.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], D Loss: 32.20570373535156, G Loss: 2.8321399688720703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 5/10 [01:23<01:23, 16.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], D Loss: 32.16664505004883, G Loss: 2.833932638168335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 6/10 [01:39<01:06, 16.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], D Loss: 32.14142990112305, G Loss: 2.8404886722564697\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 7/10 [01:56<00:49, 16.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], D Loss: 32.12034225463867, G Loss: 2.8449771404266357\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 8/10 [02:13<00:33, 16.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], D Loss: 32.08780288696289, G Loss: 2.8460283279418945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 9/10 [02:29<00:16, 16.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/10], D Loss: 32.07109069824219, G Loss: 2.8494677543640137\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [02:45<00:00, 16.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/10], D Loss: 32.058753967285156, G Loss: 2.8543262481689453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Gumbel\n",
        "num_features=22\n",
        "# Generator model\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim, num_features):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.hidden1 = nn.Linear(input_dim, 80)\n",
        "        self.hidden2 = nn.Linear(80, 80)\n",
        "\n",
        "        self.sport_hidden = nn.Linear(10, 23030)\n",
        "        self.dport_hidden = nn.Linear(10, 14372)\n",
        "        self.proto_hidden = nn.Linear(10, 7)\n",
        "\n",
        "        # self.sport_output = nn.Softmax(dim=1)\n",
        "        # self.dport_output = nn.Softmax(dim=1)\n",
        "        # self.proto_output = nn.Softmax(dim=1)\n",
        "\n",
        "        self.cont_output = nn.Linear(50, num_features - 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.hidden1(x))\n",
        "        x = torch.relu(self.hidden2(x))\n",
        "        # print(x.shape)\n",
        "        _sport_hidden = self.sport_hidden(x[:,:10])\n",
        "        _dport_hidden = self.dport_hidden(x[:,10:20])\n",
        "\n",
        "        _proto_hidden = self.proto_hidden(x[:,20:30])\n",
        "        # sport_output = self.sport_output(sport_hidden)\n",
        "        # dport_output = self.dport_output(dport_hidden)\n",
        "        # proto_output = self.proto_output(proto_hidden)\n",
        "\n",
        "        # Do not apply torch.argmax here, let the loss function handle it\n",
        "        cont_output = self.cont_output(x[:,30:])\n",
        "\n",
        "        # Concatenate the tensors along dimension 1\n",
        "        output_tensor = torch.cat((_sport_hidden, _dport_hidden, _proto_hidden, cont_output), dim=1)\n",
        "        return output_tensor\n",
        "        # return sport_output, dport_output, proto_output, cont_output\n",
        "# Discriminator model\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=100, recurrent_dropout=0.4):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # LSTM layers\n",
        "        self.lstm1 = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=True, dropout=recurrent_dropout)\n",
        "        self.lstm2 = nn.LSTM(hidden_size * 2, hidden_size, batch_first=True, bidirectional=True, dropout=recurrent_dropout)\n",
        "\n",
        "        # Batch normalization layers\n",
        "        self.batch_norm1 = nn.BatchNorm1d(hidden_size * 2)\n",
        "        self.batch_norm2 = nn.BatchNorm1d(hidden_size * 2)\n",
        "\n",
        "        # Linear output layer\n",
        "        self.output_layer = nn.Linear(hidden_size * 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # LSTM layers\n",
        "        out, _ = self.lstm1(x)\n",
        "        # print(out.shape)\n",
        "        out = self.batch_norm1(out)\n",
        "        # print(out.shape)\n",
        "        out, _ = self.lstm2(out)\n",
        "        # print(out.shape)\n",
        "        out = self.batch_norm2(out)\n",
        "        # print(out.shape)\n",
        "\n",
        "        # Global average pooling\n",
        "        # out = torch.mean(out, dim=1)\n",
        "        # print(out.shape)\n",
        "        # Output layer\n",
        "        # out = self.output_layer(out)\n",
        "        out = torch.sigmoid(self.output_layer(out))\n",
        "\n",
        "\n",
        "        return out  # Fix for the dimension mismatch\n",
        "\n",
        "# Hyperparameters\n",
        "latent_dim = 100\n",
        "data_dim = len(dataset[1])\n",
        "lr = 0.00002\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "\n",
        "# Models\n",
        "generator = Generator(latent_dim, num_features)\n",
        "discriminator = Discriminator(data_dim)\n",
        "max_grad_norm = 1.0\n",
        "# Loss function and optimizers\n",
        "criterion = nn.BCELoss()\n",
        "criterion_gen = nn.SmoothL1Loss()\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "optimizer_g = optim.Adam(generator.parameters(), lr=lr)\n",
        "optimizer_d = optim.Adam(discriminator.parameters(), lr=lr)\n",
        "\n",
        "# Training loop\n",
        "import csv\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "parameters_list = []\n",
        "dlosses = []\n",
        "glosses = []\n",
        "\n",
        "generator.train()\n",
        "discriminator.train()\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    total_loss_fake = 0\n",
        "    total_loss_real = 0\n",
        "    total_loss_gen = 0\n",
        "    for _ in data_loader:\n",
        "        # Train Discriminator\n",
        "        real_data = _\n",
        "        real_labels = torch.ones((batch_size, 1))\n",
        "        fake_labels = torch.zeros((batch_size, 1))\n",
        "\n",
        "        optimizer_d.zero_grad()\n",
        "\n",
        "        # Real data\n",
        "        # print(\"Real data: \", real_data.shape)\n",
        "        output_real = discriminator(real_data)\n",
        "        # print(output_real)\n",
        "        loss_real = criterion(output_real, real_labels)\n",
        "        # print(\"Loss:\", loss_real.item())\n",
        "        loss_real.backward()\n",
        "        # print(\"Gradients of a specific layer:\", generator.hidden1.weight.grad)\n",
        "        total_loss_real+=loss_real\n",
        "\n",
        "        # Fake data\n",
        "        noise = torch.randn(batch_size, latent_dim)\n",
        "        output = generator(noise)\n",
        "\n",
        "        sport_output = F.softmax(output[:, :23030], dim=1)\n",
        "        dport_output = F.softmax(output[:, 23030:23030+14372], dim=1)\n",
        "        proto_output = F.softmax(output[:, 23030+14372:23030+14372+7], dim=1)\n",
        "        cont_output = output[:, 23030+14372+7:]\n",
        "\n",
        "        fake_data = torch.cat((sport_output, dport_output, proto_output, cont_output), dim=1)\n",
        "\n",
        "        output_fake = discriminator(fake_data)\n",
        "        # print(output_fake)\n",
        "        # print(fake_labels)\n",
        "        loss_fake = criterion(output_fake, fake_labels)\n",
        "        loss_fake.backward()\n",
        "        total_loss_fake+=loss_fake\n",
        "        # print(\"Gradients of a specific layer:\", generator.hidden1.weight.grad)\n",
        "        optimizer_d.step()\n",
        "\n",
        "        # Train Generator\n",
        "        optimizer_g.zero_grad()\n",
        "        # generated_data = generator(noise)\n",
        "        output = generator(noise)\n",
        "        # print(fake_data.shape)\n",
        "        sport_output = F.softmax(output[:, :23030], dim=1)\n",
        "        dport_output = F.softmax(output[:, 23030:23030+14372], dim=1)\n",
        "        proto_output = F.softmax(output[:, 23030+14372:23030+14372+7], dim=1)\n",
        "        # sport_hidden = output[:, :23030]\n",
        "        # dport_hidden = output[:, 23030:23030+14372]\n",
        "        # proto_hidden = output[:, 23030+14372:23030+14372+7]\n",
        "        cont_output = output[:, 23030+14372+7:]\n",
        "        # temperature = 1.0  # You can adjust the temperature hyperparameter\n",
        "        # gumbel_dist = Gumbel(0, 1).sample(sport_hidden.shape)\n",
        "        # sport_output = F.softmax((sport_hidden + gumbel_dist) / temperature, dim=1)\n",
        "\n",
        "        # gumbel_dist = Gumbel(0, 1).sample(dport_hidden.shape)\n",
        "        # dport_output = F.softmax((dport_hidden + gumbel_dist) / temperature, dim=1)\n",
        "\n",
        "        # gumbel_dist = Gumbel(0, 1).sample(proto_hidden.shape)\n",
        "        # proto_output = F.softmax((proto_hidden + gumbel_dist) / temperature, dim=1)\n",
        "        # print(proto_output.shape)\n",
        "        # print(proto_output)\n",
        "        # print(differentiable_argmax(proto_output))\n",
        "        # print(differentiable_argmax(proto_output)[:,1])\n",
        "\n",
        "        # print(cont_output.shape)\n",
        "\n",
        "        # generated_data = torch.cat((differentiable_argmax(sport_output).unsqueeze(1),differentiable_argmax(dport_output)[:,1].unsqueeze(1),differentiable_argmax(proto_output)[:,1].unsqueeze(1), cont_output), dim=1)\n",
        "        # generated_data = torch.cat((sport_output[:,1].unsqueeze(1),dport_output[:,2].unsqueeze(1),proto_output[:,3].unsqueeze(1),cont_output), dim=1)\n",
        "        generated_data = torch.cat((sport_output, dport_output, proto_output, cont_output), dim=1)\n",
        "        # print(generated_data.shape)\n",
        "\n",
        "\n",
        "        # generated_data = convert_generator_output(generator(noise))\n",
        "        # print(generated_data.shape)\n",
        "        output_generated = discriminator(generated_data)\n",
        "        # loss_gen = criterion(output_generated, real_labels)\n",
        "        loss_gen = criterion_gen(output_generated, real_labels.float())\n",
        "        # print(\"Discriminator Output:\", output_generated)\n",
        "        # print(\"Real Labels:\", real_labels)\n",
        "        # print(\"Loss:\", loss_gen.item())\n",
        "        loss_gen.backward()\n",
        "        # torch.nn.utils.clip_grad_norm_([generator.sport_hidden.weight], max_grad_norm)\n",
        "        total_loss_gen+=loss_gen\n",
        "        # for param in generator.sport_hidden.parameters():\n",
        "        #   print(param.requires_grad)\n",
        "        # for name, param in generator.named_parameters():\n",
        "        #   if name == 'sport_hidden.weight':\n",
        "        #       print(name, param.requires_grad)\n",
        "        #       print(name, param.grad)\n",
        "        #       print(f\"{name} - Gradient Statistics: Mean={param.grad.mean()}, Std={param.grad.std()}, Min={param.grad.min()}, Max={param.grad.max()}\")\n",
        "\n",
        "        # asdasdasd\n",
        "        # print(\"Gradients of a specific layer:\", generator.sport_hidden.weight.grad)\n",
        "        optimizer_g.step()\n",
        "\n",
        "    # Print losses at the end of each epoch\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], D Loss: {total_loss_real + total_loss_fake}, G Loss: {total_loss_gen}\")\n",
        "    # print(f\"\\nEpoch {epoch + 1} - Parameters of Generator:\\n\")\n",
        "    epoch_parameters = {\"Epoch\": epoch + 1}\n",
        "    for name, param in generator.named_parameters():\n",
        "        # print(name, param.data)\n",
        "        # Store parameters in the dictionary\n",
        "        # epoch_parameters[name] = param.data\n",
        "        epoch_parameters[name] = copy.deepcopy(param.data)\n",
        "\n",
        "    # Append epoch parameters to the dictionary\n",
        "    parameters_list.append(epoch_parameters)\n",
        "    dlosses.append(loss_real + loss_fake)\n",
        "    glosses.append(loss_gen)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f702dc21510>]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# dlosses = [dloss.detach().numpy() for dloss in dlosses]\n",
        "# glosses = [gloss.detach().numpy() for gloss in glosses]\n",
        "\n",
        "# plt.figure(1)\n",
        "plt.plot(dlosses)\n",
        "# plt.figure(2)\n",
        "plt.plot(glosses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fxk8GIpLmreu",
        "outputId": "ed0ff371-daf9-47b2-9c6c-6c9a7826c92b"
      },
      "outputs": [],
      "source": [
        "# csv_file_path = \"generator_parameters_1.csv\"\n",
        "# with open(csv_file_path, mode='w', newline='') as csv_file:\n",
        "#     fieldnames = [\"Epoch\"] + list(generator.state_dict().keys())\n",
        "#     csv_writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "#     print(fieldnames)\n",
        "#     # Write the header\n",
        "#     csv_writer.writeheader()\n",
        "\n",
        "#     # Write parameters for each epoch\n",
        "#     for i in parameters_list:\n",
        "#       # print(i)\n",
        "#       # for key in i.keys():\n",
        "#       # print(i.values())\n",
        "#       print(i.keys())\n",
        "#       row = {}\n",
        "#       for key in i.keys():\n",
        "#         row[key] = i[key]\n",
        "#       print(row.keys())\n",
        "#       csv_writer.writerow(i)\n",
        "\n",
        "#       # exit\n",
        "#       # csv_writer.writerows(i.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "7T8lzE4HoNH3",
        "outputId": "b84abe31-867f-43c3-e8fe-a09b24d360f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(None, 80)\n",
            "(None, 80)\n",
            "(None, 23030)\n",
            "(None, 14372)\n",
            "(None, 7)\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "Random Input Shape: (1, 100)\n",
            "Hidden Layer Output Shape: (1, 23030)\n",
            "Sport Output Shape: (1, 14372)\n",
            "Dport Output Shape: (1, 7)\n",
            "Proto Output Shape: (1, 27)\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-496fd689432f>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dport Output Shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Proto Output Shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Continuous Output Shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Assuming num_features is defined somewhere\n",
        "num_features = 30\n",
        "\n",
        "# Assuming wasserstein_loss is defined somewhere\n",
        "def wasserstein_loss(y_true, y_pred):\n",
        "    # Placeholder for wasserstein_loss function\n",
        "    return tf.reduce_mean(y_true * y_pred)\n",
        "\n",
        "def make_generator_model(input_dim):\n",
        "    input = tf.keras.layers.Input(shape=input_dim, name=\"generator input\")\n",
        "    hidden = tf.keras.layers.Dense(80, activation=\"relu\")(input)\n",
        "    hidden = tf.keras.layers.Dense(80, activation=\"relu\")(hidden)\n",
        "    print(hidden.shape)\n",
        "    sport_hidden = tf.keras.layers.Dense(23030, name=\"sport_hidden\")(hidden)\n",
        "    dport_hidden = tf.keras.layers.Dense(14372, name=\"dport_hidden\")(hidden)\n",
        "    proto_hidden = tf.keras.layers.Dense(7, name=\"proto_hidden\")(hidden)\n",
        "    print(hidden.shape)\n",
        "    print(sport_hidden.shape)\n",
        "    print(dport_hidden.shape)\n",
        "    print(proto_hidden.shape)\n",
        "    sport_output = tf.keras.layers.Softmax(1, name=\"sport_output\")(sport_hidden)\n",
        "    dport_output = tf.keras.layers.Softmax(1, name=\"dport_output\")(dport_hidden)\n",
        "    proto_output = tf.keras.layers.Softmax(1, name=\"proto_output\")(proto_hidden)\n",
        "    cont_output = tf.keras.layers.Dense(num_features-3, name=\"cont_output\")(hidden)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input, outputs=[sport_output, dport_output, proto_output, cont_output],\n",
        "                           name=\"Generator\")\n",
        "    opt = tf.keras.optimizers.RMSprop(learning_rate=0.00005)\n",
        "    # model.compile(loss=wasserstein_loss, optimizer=opt)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Assuming input_dim is 100 for example\n",
        "input_dim = 100\n",
        "\n",
        "# Create a random input tensor for testing\n",
        "random_input = np.random.rand(1, input_dim)\n",
        "\n",
        "# Instantiate the generator model\n",
        "generator_model = make_generator_model(input_dim)\n",
        "\n",
        "# Forward pass through the generator\n",
        "output_tensors = generator_model.predict(random_input)\n",
        "\n",
        "# Display the shapes after each step\n",
        "print(\"Random Input Shape:\", random_input.shape)\n",
        "print(\"Hidden Layer Output Shape:\", output_tensors[0].shape)\n",
        "print(\"Sport Output Shape:\", output_tensors[1].shape)\n",
        "print(\"Dport Output Shape:\", output_tensors[2].shape)\n",
        "print(\"Proto Output Shape:\", output_tensors[3].shape)\n",
        "print(\"Continuous Output Shape:\", output_tensors[4].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCpmnS0K_ywD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ankh-morpork",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
