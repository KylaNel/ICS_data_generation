{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not subclassing prevents using different behaviour in training and in generation. Means dropout is not an option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 14:24:57.699734: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-25 14:24:57.721986: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-25 14:24:57.722008: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-25 14:24:57.722023: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-25 14:24:57.726205: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-25 14:24:57.726530: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-25 14:24:58.436934: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "import scipy\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get in dataset\n",
    "attacks = pd.read_csv(\"/home/knel/virtual_envs/ankh-morpork/ICS_data_generation/data/csvDataFeaturesTest.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks = preprocessing.normalize(attacks.to_numpy(), norm=\"max\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248278, 22)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should probably add batch and shuffle\n",
    "\n",
    "train_dataset = attacks[:int(np.floor(attacks.shape[0]*3/4))]\n",
    "test_dataset = attacks[int(np.floor(attacks.shape[0]*3/4)):]\n",
    "\n",
    "# buffer_size = 10000\n",
    "# batch_size = 50\n",
    "\n",
    "# train_dataset = (tf.data.Dataset.from_tensor_slices(attacks[:int(np.floor(attacks.shape[0]*3/4))]).shuffle(buffer_size).batch(batch_size))\n",
    "# test_dataset = (tf.data.Dataset.from_tensor_slices(attacks[int(np.floor(attacks.shape[0]*3/4)):]).shuffle(buffer_size).batch(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        mean, log_var = inputs\n",
    "        return tf.keras.backend.random_normal(tf.shape(log_var)) * tf.keras.backend.exp(log_var / 2) + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "codings_size = 100\n",
    "num_features = attacks[:int(np.floor(attacks.shape[0]*3/4))].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=[num_features,1])\n",
    "z = tf.keras.layers.Flatten()(inputs)\n",
    "z = tf.keras.layers.Dense(150, activation=\"relu\", kernel_initializer=\"he_normal\")(z)\n",
    "z = tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\")(z)\n",
    "codings_mean = tf.keras.layers.Dense(codings_size)(z) # mu\n",
    "codings_log_var = tf.keras.layers.Dense(codings_size)(z) # gamma\n",
    "codings = Sampling()([codings_mean, codings_log_var])\n",
    "variational_encoder = tf.keras.Model(inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "\n",
    "decoder_inputs = tf.keras.layers.Input(shape=[codings_size])\n",
    "x = tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\")(decoder_inputs)\n",
    "x = tf.keras.layers.Dense(150, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.Dense(num_features*1, activation=\"sigmoid\")(x)\n",
    "outputs = tf.keras.layers.Reshape([num_features, 1])(x)\n",
    "variational_decoder = tf.keras.Model(inputs=[decoder_inputs], outputs=[outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE model\n",
    "\n",
    "_, _, codings = variational_encoder(inputs)\n",
    "reconstructions = variational_decoder(codings)\n",
    "variational_ae = tf.keras.Model(inputs=[inputs], outputs=[reconstructions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses\n",
    "\n",
    "latent_loss = -0.5 * tf.keras.backend.sum(1 + codings_log_var - tf.keras.backend.exp(codings_log_var) - tf.keras.backend.square(codings_mean), axis=-1)\n",
    "variational_ae.add_loss(tf.keras.backend.mean(latent_loss / float(num_features)))\n",
    "# variational_ae.add_loss(tf.keras.backend.mean(latent_loss))\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-5)\n",
    "variational_ae.compile(loss=\"binary_crossentropy\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "18621/18621 [==============================] - 15s 776us/step - loss: 0.4292\n",
      "Epoch 2/15\n",
      "18621/18621 [==============================] - 15s 783us/step - loss: 0.3167\n",
      "Epoch 3/15\n",
      "18621/18621 [==============================] - 14s 777us/step - loss: 0.3057\n",
      "Epoch 4/15\n",
      "18621/18621 [==============================] - 15s 779us/step - loss: 0.2991\n",
      "Epoch 5/15\n",
      "18621/18621 [==============================] - 14s 778us/step - loss: 0.2946\n",
      "Epoch 6/15\n",
      "18621/18621 [==============================] - 15s 783us/step - loss: 0.2899\n",
      "Epoch 7/15\n",
      "18621/18621 [==============================] - 15s 785us/step - loss: 0.2870\n",
      "Epoch 8/15\n",
      "18621/18621 [==============================] - 15s 781us/step - loss: 0.2851\n",
      "Epoch 9/15\n",
      "18621/18621 [==============================] - 15s 784us/step - loss: 0.2837\n",
      "Epoch 10/15\n",
      "18621/18621 [==============================] - 15s 782us/step - loss: 0.2823\n",
      "Epoch 11/15\n",
      "18621/18621 [==============================] - 15s 780us/step - loss: 0.2812\n",
      "Epoch 12/15\n",
      "18621/18621 [==============================] - 15s 783us/step - loss: 0.2801\n",
      "Epoch 13/15\n",
      "18621/18621 [==============================] - 15s 780us/step - loss: 0.2795\n",
      "Epoch 14/15\n",
      "18621/18621 [==============================] - 15s 780us/step - loss: 0.2782\n",
      "Epoch 15/15\n",
      "18621/18621 [==============================] - 15s 780us/step - loss: 0.2778\n"
     ]
    }
   ],
   "source": [
    "history = variational_ae.fit(train_dataset, train_dataset, epochs=15, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940/1940 [==============================] - 1s 584us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.619777523909955, pvalue=0.0, statistic_location=0.0, statistic_sign=1)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = variational_ae.predict(test_dataset)\n",
    "\n",
    "num_values = test_dataset.shape[0] * test_dataset.shape[1]\n",
    "\n",
    "scipy.stats.ks_2samp(test_dataset.reshape(num_values,), predictions.reshape(num_values,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.016145012790877433, pvalue=2.633356377928654e-232, statistic_location=0.9596774193548391, statistic_sign=1)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.ks_2samp(test_dataset.reshape(num_values,), train_dataset.reshape(train_dataset.shape[0] * train_dataset.shape[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ankh-morpork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
